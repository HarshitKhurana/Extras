
### [\*] Types of Problems

|Type       |  Regression           | Classification                  | Clustering                       | 
|-----------|---------------        |--------------                   |-----------------                 |
|Output     |  Continous value      | Categorical quantity            | assign data point to clusters    | 
|ML Type    |  Supervised           | Supervised                      | Un-Supervised                    | 
|Usage      |  For predections      | For computing category          | To group similar items cluster   | 
|Algo       |  Linear Regression    | Logistic Regression             | K-Means                          | 
|Example    |  Predict stock value  | classify email as spam/non-spam | Find all fraudulent transactions | 


### [\*] Algorithms
 <a href="./SupervisedLearning.md"> 1. Supervised Algos</a> </br>
 <a href="./UnSupervisedLearning.md"> 2. Un-supervised Algos</a> </br>
 <a href="./ReinforcementLearning.md"> 3. Reinforcement Learning</a> </br>

#### [\*] Limitation of ML
1. With more number of dimensions, the complexity of the problem increases which restrtics ML usage. Eg: Image recognition, NLP etc
2. Harder to tell an ML mopdel which features it should look for which will play an imp role in getting more accuratre results (this is called Feature Extraction.) 

### [\*] Deep Learning: 
  * Subset of ML used for solving complex problems.
  * Deep Learning has the only methods which can be used for feature Extraction, as these algos by themselves can find out the right features by themselves i.e Feature Extraction occurs automatically.
  * Inspired from Brain neurons (but is not directly biological neuron, since we dont know exactly how the brain works.)
  * It is a collection of statistical machine learning techniques used to learn featurre hierarchies based on the concept of artificial neural networks.

#### [\*] Terminology:
  * **Perceptron:** It is a linear model used for binary classification, it is used to model a neuron which has set of weighted inputs on which some function 'f(x)' is computed and gives a binary output.
  * **Activation/Transfer function:** These are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (“fired”) or not, based on whether each neuron’s input is relevant for the model’s prediction
  * **Feed Forward Neural Network:** It means that every node at each level is connected to every other node(at next level).
  * **Gradient Descent:** This method is used to adjust weights in the network with aim of reducing the error at output layer.

#### 1. Single layer perceptron (SLP) : 
  * It is a **feed-forward network** based on a threshold transfer function. SLP is the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target (1 , 0).
  * It only has input and output layer (no hidden/intertnal layer)
  * Dis-adv:
    - Cannot segregate non-linear data.

#### 2. Multi-layer Perceptron: 
  * It has the same structure of a single layer perceptron but with one or more hidden layers & is thus considered **Deep Neural Network**.
  * It has multiple hidden layers
  * Randomly assigns weights to the input.
  * To ensure that the weights assigned randomly (in above step) are correct, **Backpropogation** is added, using backpropogation the model/layer can update the weight of the previous layer in order to minimise the output error and improve accuracy.

#### &nbsp; &nbsp; &nbsp; &nbsp; [\*] Limitation:
 &nbsp; &nbsp; &nbsp; &nbsp;  * A trained FeedForward network can be exposed to any random collection of photos, and the first photo it is exposed to will not necessarily alter how it classifies the second one. (ncoz the model is already generated and the wqeights are assigned)
  Eg: Predicting a word in a sentence, after a word there is only a subset of word that can come next , but our model can't handle that.
</br>

 &nbsp; &nbsp; &nbsp; &nbsp; * So FeedForward networkd can't be used in the scenarios where the output is based on the previous outcomes.

#### 3. Recurrent Neural Network:
  * To solve the limitaion of FeedForward network, these are introduced: 
    * In this, when we have generated an output say 'x' at time 't' then some info from this output will be fed to the input when generating output at time 't+1'
  * These are ANN used to recogonize patterns in sequences of data , eg: text, gnomes, handwriting , sentences, stock market etc.
        
#### 4. Convolutional Neural Network:
  * Now imagine that we have to process a data having huge number of input/features, now to process these we would need even higher number of layers/neurons for better processing and once we connect all the neurons in a layer to neurons/node in other layer there is a high chance that it may lead to over-fitting, thus to avoid this **CNN** are formed.
  * In CNN, the neuron in a layer will only be conencted to a small region of layer before it(instead of all of the neurons in a faully-connected manner)


